{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_summary.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/Jo0BIgR3FyYvKpWVVT9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhky/Full_YOLO/blob/master/YOLO_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be-R1p6Cobax",
        "colab_type": "text"
      },
      "source": [
        "# **1.Giới thiệu chung**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkQJgeJJouLo",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. YOLO là gì \n",
        "You only look once (Chỉ cẩn nhìn 1 lần) là có thể phát hiện ra vật thể (Rất nhanh rất nhanh)\n",
        "\n",
        "YOLO không phải là thuật toán tốt nhất nhưng là thuật toán nhanh nhất trong các mô hình object detection => Real time\n",
        "\n",
        "**Mục tiêu**\n",
        "- Dự báo nhãn dán (lable) bài toán phân lớp classification \n",
        "- Xác định location của vật thể ( xác định đươc nhiều vật thể trong 1 ảnh)\n",
        "\n",
        "**Yêu cầu**\n",
        "- Convolution Neural Network \n",
        "- Bounding box, anchor box, Feature map, Non-max suppression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY0FCx0SqtWw",
        "colab_type": "text"
      },
      "source": [
        "# **2. Kiến trúc mạng YOLO**\n",
        "Bao gồm 2 thành phần\n",
        "- base network : Là các mạng convolution làm nhiệm vụ trích xuất đặc trưng. \n",
        "- Extra Layers: Được áp dụng để phát hiện vật thể trên feature map của base network.\n",
        "\n",
        "  ![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h1.png)**Hình 1:** Sơ đồ kiến trúc mạng YOLO.\n",
        "- base network: DarkNet Architecture.Output của base network là mộ feature map 7x7x1024, feature map 7x7x30\n",
        "- Etra layers: các phần phía sau\n",
        "\n",
        "YOLO verion 3: Sử dụng mạng feature extractor là darknet-53\n",
        "Mạng này bao gồm\n",
        "-  53 convolutional layers kết nối liên tiếp. Mỗi layer được theo sau bởi 1 batch normalization + activation Leaky Relu + sử dụng bộ lọc (filter = 2) (để giảm thiểu số lượng tham số)\n",
        "\n",
        "  ![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h2.png)Hình 2: Các layer trong mạng darknet-53\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFC4vdUC0PoG",
        "colab_type": "text"
      },
      "source": [
        "# **3. Input và Output của YOLO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_w8SO4P0oeA",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Input \n",
        "Các bức ảnh \n",
        "\n",
        "Các bức ảnh sẽ được scale chung về một kích thước phù hợp với input shape trước khi vào các convolution và sẽ được giảm dần theo cấp số nhân 2 khi đi qua các layer convolution, ta thu được feature map kích thước tương đối nhỏ để dự báo trên từng ô của feature \n",
        "\n",
        "**input shape của YOLO**\n",
        "- input 416x416 => feature map 13x13, 26x26 và 52x52\n",
        "- input 608x608 => feature map 19x19, 38x38 và 72x72"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-c36N381CVZ",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Output\n",
        "\n",
        "Output của mô hình YOLO là 1 vector bao gồm các thành phần\n",
        "\n",
        "  ![Texte alternatif…](https://latex.codecogs.com/png.latex?\\inline&space;\\dpi{150}&space;\\bg_green&space;y^{T}&space;=&space;[p_0,\\langle\\underbrace{t_x,&space;t_y,&space;t_w,&space;t_h}_{\\text{bounding&space;box}}\\rangle,&space;\\langle\\underbrace{p_1,&space;p_2,...,&space;p_c}_{\\text{scores&space;of&space;c&space;classes}}\\rangle])\n",
        "\n",
        "Trong đó \n",
        "\n",
        "- ![Texte alternatif…](https://latex.codecogs.com/png.latex?\\inline&space;\\dpi{150}&space;\\bg_green&space;p_0)  là xác suất dự báo vật thể xuất hiện trong bounding box.\n",
        "\n",
        "- ![Texte alternatif…](https://latex.codecogs.com/png.latex?\\inline&space;\\dpi{150}&space;\\bg_green&space;\\langle\\underbrace{t_x,&space;t_y,&space;t_w,&space;t_h}_{\\text{bounding&space;box}}\\rangle) giúp xác định bounding box\n",
        "\n",
        "- ![Texte alternatif…](https://latex.codecogs.com/png.latex?\\inline&space;\\dpi{150}&space;\\bg_green&space;\\langle\\underbrace{p_1,&space;p_2,...,&space;p_c}_{\\text{scores&space;of&space;c&space;classes}}\\rangle) là vector phân phối xác xuất dự báo\n",
        "\n",
        "\n",
        "Việc hiểu output khá là quan trọng để chúng ta cấu hình tham số chuẩn xác khi huấn luyện model qua các open source như darknet. \n",
        "\n",
        "Như vậy output sẽ được xác định theo số lượng classes theo công thức (n_class+5).\n",
        "\n",
        "Nếu huấn luyện 80 classes thì bạn sẽ có output là 85. \n",
        "\n",
        "Trường hợp bạn áp dụng 3 anchors/cell thì số lượng tham số output sẽ là: (n_class+5)×3=85×3=255\n",
        "\n",
        "![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h3.png) **HÌNH 3** Kiến trúc ouput của YOLO \n",
        "\n",
        "- feature map kích thước 13x13. \n",
        "- Trên mỗi cell lấy ra 3 anchor boxes: Tâm của anchor Box1, Box2, Box3 trùng với cell \n",
        "- Khi đó output của YOLO là một vector concatenate của 3 bounding boxes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkVw9WpzCK5B",
        "colab_type": "text"
      },
      "source": [
        "# **4. Dự báo trên nhiều feature**\n",
        "Feature map ban đầu có kích thước nhỏ giúp => dự đoán các object kích thước lớn.\n",
        "\n",
        "Feature map sau có kích thước lớn, mà anchor box không thay đổi => dự đoán các object kích thước nhỏ\n",
        "\n",
        "  ![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h4.png) **Hình 4** Các feature maps của mạng YOLOv3 với input shape là 416x416, output là 3 feature maps có kích thước lần lượt là 13x13, 26x26 và 52x52.\n",
        "\n",
        "Trên mỗi một cell của các feature map chúng ta sẽ áp dụng 3 anchor box để dự đoán vật thể. Như vậy số lượng các anchor box khác nhau trong một mô hình YOLO sẽ là 9 (3 featue map x 3 anchor box).\n",
        "\n",
        "Đồng thời trên một feature map hình vuông S x S, mô hình YOLOv3 sinh ra một số lượng anchor box là: S x S x 3. Như vậy số lượng anchor boxes trên một bức ảnh sẽ là: (13×13+26×26+52×52)×3=10647(anchor boxes)\n",
        "\n",
        "Đây là một số lượng rất lớn và là nguyên nhân khiến quá trình huấn luyện mô hình YOLO vô cùng chậm bởi chúng ta cần dự báo đồng thời nhãn và bounding box trên đồng thời 10647 bounding boxes.\n",
        "\n",
        "**Một số lưu ý khi huấn luyện YOLO:**\n",
        "\n",
        "Khi huấn luyện YOLO sẽ cần phải có RAM dung lượng lớn hơn để save được 10647 bounding boxes như trong kiến trúc này.\n",
        "\n",
        "Không thể thiết lập các batch_size quá lớn như trong các mô hình classification vì rất dễ Out of memory.\n",
        "\n",
        "Package darknet của YOLO đã chia nhỏ một batch thành các subdivisions cho vừa với RAM.\n",
        "\n",
        "Thời gian xử lý của một step trên YOLO lâu hơn rất rất nhiều lần so với các mô hình classification. Do đó nên thiết lập steps giới hạn huấn luyện cho YOLO nhỏ.\n",
        "\n",
        "Đối với các tác vụ nhận diện dưới 5 classes, dưới 5000 steps là có thể thu được nghiệm tạm chấp nhận được. Các mô hình có nhiều classes hơn có thể tăng số lượng steps theo cấp số nhân tùy bạn. ( sẽ thực hiện bài tập ở bài sau)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHiR9OgbGLv2",
        "colab_type": "text"
      },
      "source": [
        "# **5. Anchor box**\n",
        "Anchor box làm cơ sở ước lượng để tìm được bounding box trong vậy thể.\n",
        "\n",
        "Thuật toán regression box sẽ tinh chỉnh anchor box để tạo ra bounding box\n",
        "\n",
        "- Một vật thể trong hình ảnh huấn luyện được phân bổ về một cell trên featute map có chứa điểm mid poin của vật thể.\n",
        "- Từ trong cell ta xác định các anchor bao quanh vật thể, nếu có nhiều hơn 2 anchor box sẽ chọn anchor box có IoU so với ground truth bounding box là cao nhất .\n",
        "\n",
        "***=> Xác định vật thể cần 2 thành phần ( cell và anchor box)***\n",
        "\n",
        "![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h5.png)**Hình 5:** Xác định anchor box cho một vật thể\n",
        "\n",
        "Một số trường hợp 2 vật thể bị trùng mid point, mặc dù rất hiếm khi xảy ra, thuật toán sẽ rất khó xác định được class cho chúng.\n",
        "\n",
        "![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h6.jpg) **Hinh 6:** Hai vật thể trùng mid point và cùng thuộc 1 cell => Thuật toán cần thêm lượt tiebreak để quyết định đâu là class cho cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxk-eabo3A09",
        "colab_type": "text"
      },
      "source": [
        "# **6. Hàm loss function** \n",
        "\n",
        "SSD và YOLO \n",
        "\n",
        "Hàm loss function chia thành 2 phần: localization loss và confidence loss.\n",
        "- location loss: Hàm mất mát của bounding box dự báo so với thực tế.\n",
        "- confidence los: Hàm phân phối xác suất. \n",
        "\n",
        "Mình chưa hiểu rõ : Ai đó có thể góp ý với mình qua gmail: anhkypropy@gmail.com\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4YuwSkMmUKo",
        "colab_type": "text"
      },
      "source": [
        "# **7. Dự báo bounding box**\n",
        "(YOLO version 2 và version 3) \n",
        "Tọa độ của một bounding box sẽ được xác định dựa trên đồng thời cả anchor box và cell mà nó thuộc về = >  giúp kiểm soát vị trí của bounding box dự đoán đâu đó quanh vị trí của cell và bounding box mà không vượt quá xa ra bên ngoài giới hạn version 1\n",
        "\n",
        "![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h7.png)\n",
        "\n",
        "**Hình 7** Công thức ước lượng bounding box từ anchor box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6m4VHfLqlW2",
        "colab_type": "text"
      },
      "source": [
        "# **8. Non-max suppression**\n",
        "Xem lại mục Non-max suppression để hiểu rõ hơn.\n",
        "\n",
        "Do thuật toán YOLO dự báo ra rất nhiều bounding box trên một bức ảnh nên đối với những cell có vị trí gần nhau, khả năng các khung hình bị overlap là rất cao => Dùng non-max suppression để giảm bớt số lượng khung hình có độ chính xác thấp\n",
        "\n",
        "![Texte alternatif…](https://phamdinhkhanh.github.io/assets/images/20200309_YOLOAlgorithm/h8.png) \n",
        "\n",
        "**Hình 8** Sử dụng non-max-suppression \n",
        "\n",
        "**Các bước của non-max suppression:**\n",
        "- Step 1: giảm số lượn bounding box bằng cách lọc bỏ nhũng bounding box có xác suất chứa vật thể nhỏ hơn một ngưỡng threhold, thường là 0.5\n",
        "- Step 2: Đối với nhũng bounding box giao nhau, non-max suppression chọn ra những bounding box có xác xuất chứa vật thể là lớn nhất. Sau đó tính chỉ số giao thoa IoU với các bounding box còn lại.\n",
        "\n",
        "Nếu chỉ số lớn hơn ngưỡng threhold cho phép chứng tỏ 2 bounding box bị overlap rất cao (Qua mặt bước 1) => (Đến bước 2) xóa bỏ các bounding box có xác xuất chưa vật thể thấp => Thu dược bounding box duy nhất cho vật thể. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cvl6NOc2R4h",
        "colab_type": "text"
      },
      "source": [
        "# **9.Cũng cố**\n",
        "Cũng cố lại kiến thức về anchor box, bounding box, feature nap, Non-max suppression, Đặc biệt là nguyên lý hoạt động của Convolution Neural Network."
      ]
    }
  ]
}